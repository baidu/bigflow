
package baidu.bigflow.service;

import "bigflow_python/proto/pipeline.proto";
import "bigflow_python/proto/python_resource.proto";
import "flume/proto/logical_plan.proto";
import "flume/proto/config.proto";

option cc_generic_services = true;
option py_generic_services = true;

/////////////////////////////////////////////
//  Request/Reponse Interface Definitions
/////////////////////////////////////////////

message ResponseStatus {
    optional bool success = 1;
    optional string reason = 2;
}

message LaunchRequest {
    optional string pipeline_id = 1;
    optional baidu.flume.PbLogicalPlan logical_plan = 2;
    optional baidu.bigflow.python.PbPythonResource resource = 3;
    repeated string hadoop_commit_args = 4;
    optional bytes pipeline_context = 5;
}

message SuspendRequest {
    optional string pipeline_id = 1;
    optional baidu.flume.PbLogicalPlan logical_plan = 2;
    repeated string hadoop_commit_args = 3;
}

message KillRequest {
    optional string pipeline_id = 1;
    optional baidu.flume.PbLogicalPlan logical_plan = 2;
    repeated string hadoop_commit_args = 3;
}

message VoidResponse {
    optional ResponseStatus status = 1;
}

message GetStatusRequest {
    optional string pipeline_id = 1;
    optional baidu.flume.PbLogicalPlan logical_plan = 2;
    repeated string hadoop_commit_args = 3;
}

message GetStatusResponse {
    enum Status {
        AM_SUBMIT = 0;
        AM_ALLOCATE = 1;
        AM_RUN = 2;
        AM_KILL = 3;
        AM_FAIL = 4;
        AM_UNKNOWN = 5;

        APP_SUBMIT = 100;
        APP_ALLOCATE = 101;
        APP_RUN = 102;
        APP_KILL = 103;
        APP_FAIL = 104;
        APP_UNKNOWN = 105;
    };
    optional ResponseStatus status = 1;
    optional Status app_status = 2;
}

message RegisterPipelineRequest {
    optional PbPipeline pipeline = 1;
    optional string pipeline_id = 2;
}

message UnRegisterPipelineRequest {
    optional string pipeline_id = 1;
}

message WriteLocalSeqFileRequest {
    optional string file_path = 1;
    repeated bytes key = 2;
    repeated bytes value = 3;
}

message SingleStringRequest {
    optional string request = 1;
}

message SingleStringResponse {
    optional ResponseStatus status = 1;
    optional bytes response = 2;
}

message SingleBooleanResponse {
    optional ResponseStatus status = 1;
    optional bool response = 2;
}

message GetToftStylePathRequest {
    optional string input_path = 1;
    optional string hadoop_conf_path = 2;
    optional string fs_defaultfs = 3;
    optional string hadoop_job_ugi = 4;
}

message IsNodeCachedRequest {
    optional string pipeline_id = 1;
    optional string node_id = 2;
}

message HadoopCommitRequest {
    optional string hadoop_client_path = 1;
    optional string hadoop_config_path = 2;
    repeated string args = 3;
}

message GetCachedDataRequest {
    optional string pipeline_id = 1;
    optional string node_id = 2;
}

message GetCachedDataResponse {
    optional ResponseStatus status = 1;
    repeated KeysValue keys_value = 2;
}

message KeysValue {
    repeated bytes key = 1;
    optional bytes value = 2;
}

message GetMetaInfoRequest {
    optional bytes config = 1;
}

message GetMetaInfoResponse {
    repeated bytes field_name = 1;
    optional bytes serialized_context = 2;
}

message GetCountersRequest {
    optional string pipeline_id = 1;
}

message GetCountersResponse {
    optional ResponseStatus status = 1;
    repeated string name = 2;
    repeated uint64 value = 3;
}

message ResetCounterRequest {
    optional string pipeline_id = 1;
    optional string name = 2;
}

message ResetCounterResponse {
    optional ResponseStatus status = 1;
}

message ResetAllCountersRequest {
    optional string pipeline_id = 1;
}

message ResetAllCountersResponse {
    optional ResponseStatus status = 1;
}

/////////////////////////////////////////////
//  Available Services
/////////////////////////////////////////////

service BigflowService {
    rpc register_pipeline(RegisterPipelineRequest) returns (VoidResponse);
    rpc unregister_pipeline(UnRegisterPipelineRequest) returns (VoidResponse);
    rpc launch(LaunchRequest) returns (VoidResponse);
    rpc suspend(SuspendRequest) returns (VoidResponse);
    rpc kill(KillRequest) returns (VoidResponse);
    rpc get_status(GetStatusRequest) returns (GetStatusResponse);
    rpc write_local_seqfile(WriteLocalSeqFileRequest) returns (VoidResponse);
    rpc default_hadoop_config_path(SingleStringRequest) returns (SingleStringResponse);
    rpc default_hadoop_client_path(SingleStringRequest) returns (SingleStringResponse);
    rpc default_fs_defaultfs(SingleStringRequest) returns (SingleStringResponse);
    rpc default_hadoop_job_ugi(SingleStringRequest) returns (SingleStringResponse);
    rpc default_spark_home_path(SingleStringRequest) returns (SingleStringResponse);
    rpc tmp_local_path(SingleStringRequest) returns (SingleStringResponse);
    rpc tmp_hdfs_path(SingleStringRequest) returns (SingleStringResponse);
    rpc hadoop_commit(HadoopCommitRequest) returns (VoidResponse);
    rpc get_toft_style_path(GetToftStylePathRequest) returns (SingleStringResponse);
    rpc is_node_cached(IsNodeCachedRequest) returns (SingleBooleanResponse);
    rpc get_cached_data(GetCachedDataRequest) returns (GetCachedDataResponse);
    rpc get_meta_info(GetMetaInfoRequest) returns (GetMetaInfoResponse);
    rpc get_counters(GetCountersRequest) returns (GetCountersResponse);
    rpc reset_counter(ResetCounterRequest) returns (ResetCounterResponse);
    rpc reset_all_counters(ResetAllCountersRequest) returns (ResetAllCountersResponse);
}
