# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, Baidu
# This file is distributed under the same license as the Bigflow Python
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Bigflow Python 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-01-02 17:07+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.5.1\n"

#: ../../design/fields.rst:2
msgid "SchemaPCollection设计文档"
msgstr ""

#: ../../design/fields.rst:5
msgid "设计目的"
msgstr ""

#: ../../design/fields.rst:7
msgid ""
"虽然Bigflow现有接口较spark等同类系统抽象层次更高，嵌套数据集已经使得代码复用上有了较大优势， "
"但因为无字段支持，在字段需求明显时，使用bigflow会降低代码的可读性，且实现也略为复杂。"
msgstr ""

#: ../../design/fields.rst:10
msgid "例如，bigflow中较常见下面的代码：::"
msgstr ""

#: ../../design/fields.rst:15
msgid "这种代码一是无法复用sum（甚至更复杂的）函数， 二是如果列数较多且各列做的操作不同时，从下标很难知道每列是干什么的，代码阅读起来困难。"
msgstr ""

#: ../../design/fields.rst:18
msgid "所以，希望能够提供一套类似于spark上的DataFrame的系统，对字段操作进行支持。"
msgstr ""

#: ../../design/fields.rst:21
msgid "设计目标"
msgstr ""

#: ../../design/fields.rst:23
msgid "支持字段操作功能"
msgstr ""

#: ../../design/fields.rst:24
msgid "进一步提升Bigflow用户代码可重用性"
msgstr ""

#: ../../design/fields.rst:25
msgid "用户尽可能容易理解"
msgstr ""

#: ../../design/fields.rst:26
msgid "额外的开销尽可能少"
msgstr ""

#: ../../design/fields.rst:27
msgid "用户代码量尽可能减少"
msgstr ""

#: ../../design/fields.rst:29
msgid ""
"其中，优先级从上到下依次降低，当发生严重冲突时，一般取上边的目标。 关于“用户代码量尽可能减少”这个目标，本方案不作为重心， "
"因为减少代码量可以在基础的接口之上再想办法提供一些上层库，包装一下来实现， 甚至有了基本API之后用户都能轻松的包装出来一些能减少代码量的函数。"
msgstr ""

#: ../../design/fields.rst:35
msgid "接口设计"
msgstr ""

#: ../../design/fields.rst:38
msgid "接口说明"
msgstr ""

#: ../../design/fields.rst:41
msgid "基本接口"
msgstr ""

#: ../../design/fields.rst:43
msgid ""
"提供一种PCollection，称为SchemaPCollection，用来表示结构化的，带字段的PCollection， "
"它拥有普通PCollection的所有操作，可以直接当作每个元素是一个dict的PCollection来用。"
msgstr ""

#: ../../design/fields.rst:46
msgid "细节参考："
msgstr ""

#: ../../design/fields.rst:48
msgid ":mod:`schema <bigflow.schema>`"
msgstr ""

#: ../../design/fields.rst:50
msgid "原则上，select/agg都应支持side_input / broadcast。"
msgstr ""

#: ../../design/fields.rst:52
msgid "以上接口为基本接口，在以上接口上，还需要实现出众多辅助API，如join/distinct/sort_by。"
msgstr ""

#: ../../design/fields.rst:55
msgid "PObject上添加操作符重载"
msgstr ""

#: ../../design/fields.rst:57
msgid "让PObject支持以下操作符重载:"
msgstr ""

#: ../../design/fields.rst:61 ../../design/fields.rst:84
#: ../../design/fields.rst:226
msgid "例如："
msgstr ""

#: ../../design/fields.rst:71
msgid "注意，需要支持右操作符不是PObject。"
msgstr ""

#: ../../design/fields.rst:75
msgid "有了这些操作符之后，可以使得用户写出的代码更为直观。"
msgstr ""

#: ../../design/fields.rst:78
msgid "输入输出"
msgstr ""

#: ../../design/fields.rst:80
msgid ""
"另提供input.SchemaTextFile类和output.SchemaTextFile类， "
"支持用某种分隔符分隔的文件直接读取成SchemaPCollection， 或者将SchemaPCollection直接write到外部存储。"
msgstr ""

#: ../../design/fields.rst:94
msgid "代码示范"
msgstr ""

#: ../../design/fields.rst:96
msgid ""
"输入数据第一列为websites，第二列为clicknum。 现需求是将websites按逗号拆分成website。 "
"然后按website分组，求出每个website总clicknum, 最大clicknum，以及平均clicknum。"
msgstr ""

#: ../../design/fields.rst:140
msgid "设计折衷点"
msgstr ""

#: ../../design/fields.rst:142
msgid "与DataFrame的比较"
msgstr ""

#: ../../design/fields.rst:144
msgid "如下是DataFrame代码："
msgstr ""

#: ../../design/fields.rst:152
msgid ""
"较本文中所描述的方案，在合适的情况下，由于默认不改变字段的命名，不需要为每个字段都重命名， "
"且由于DataFrame提供了大量的API接口，且每个接口都接收多种不同风格的参数，所以， "
"每处如果选对合适风格的合适的API接口，代码量会可能会比前述接口代码量更少，并且直观上也更像SQL。"
msgstr ""

#: ../../design/fields.rst:156
msgid "但DataFrame相关接口有以下缺点："
msgstr ""

#: ../../design/fields.rst:158
msgid "需要提供max/min/count等UDF，且UDF都是处理单机数据集的，无法进行高级优化，无法复用旧的sum/count等操作。"
msgstr ""

#: ../../design/fields.rst:159
msgid "字段上可进行的操作极其有限，且扩展起来困难。用户已实现的任意分布式算法都无法复用，如用户实现了个count_distinct，后来需要在某字段上使用时，发现无法复用。"
msgstr ""

#: ../../design/fields.rst:160
msgid "用户自定义UDF需要派生自某几个特定的类，书写起来略为复杂。"
msgstr ""

#: ../../design/fields.rst:161
msgid "需要提供数量众多的API才能完成完整的语义，学习成本较大。"
msgstr ""

#: ../../design/fields.rst:163
msgid ""
"换句话说，Bigflow上述API，主要提供了两个新语义：select/agg，其它的语义在Bigflow中都原来已存在， "
"即使有改变，也都极其相似。在添加了这两个新操作之后，可以与旧的任意操作任意组合， "
"进而拼接完成一切完备的功能，而DataFrame则为了表达完整语义，提供了大量不同的基本接口， "
"且每个接口都提供了数种不同风格的参数，用户学习成本较大；且除显式转回旧风格rdd外， 没有任何办法复用旧有代码。"
msgstr ""

#: ../../design/fields.rst:169
msgid "当然，我们也可以同时提供上述风格以及我们的风格的API， 但无法避免DataFrame本来就有的接口风格不统一，太过庞杂的问题。"
msgstr ""

#: ../../design/fields.rst:172
msgid ""
"而关于使用bigflow在一些代码书写时，可能会代码量略大于spark的问题， "
"由于用户可以很轻松的在我们的API上包装出spark类似的API，所以，问题不大。"
msgstr ""

#: ../../design/fields.rst:175
msgid "为何不直接让普通的元素为dict的PCollection上即可进行上述操作，而要添加特殊的类型？"
msgstr ""

#: ../../design/fields.rst:177
msgid ""
"如果使用上述接口，普通的PCollection因为不知道有哪些字段，无法拼出select_fn/agg_fn的参数， "
"但，但如果把传入的参数改为一个特殊实现的类型， "
"在调用中括号操作符时才去生成相应字段对应的PCollection(PObject)，或者把把接口改成下面的样子：::"
msgstr ""

#: ../../design/fields.rst:186
msgid "则都可以在及时拿到输入字段，拼出用户要求的数据集。"
msgstr ""

#: ../../design/fields.rst:188
msgid ""
"此方案优点是用户可以在任意每个元素为dict的PCollection上进行字段操作， "
"不需要多一步从别的类型转成SchemaPCollection的操作。"
msgstr ""

#: ../../design/fields.rst:191
msgid "但有以下劣势： 1. 即使我们提供了from_tuple/to_tuple函数，用户也可能会认为此函数与手工转化效率相同，而直接手工转换。"
msgstr ""

#: ../../design/fields.rst:193
msgid "但实际上，使用这些函数，能够避免计算中间出现dict，从而使得计算效率大大提升。"
msgstr ""

#: ../../design/fields.rst:194
msgid "较难支持以下用法，p.select(lambda cols: cols.update({'a': cols['a'] + 1}) or cols)。"
msgstr ""

#: ../../design/fields.rst:195
msgid "这样表示只改变少量字段。"
msgstr ""

#: ../../design/fields.rst:196
msgid "无法从语法层面避免输出字段重复，用户较难发现这个错误的用法，需要在运行层检查。"
msgstr ""

#: ../../design/fields.rst:197
msgid "需要传入许多函数，需要每个输出字段都指明需要哪几个输入字段，较为繁琐。"
msgstr ""

#: ../../design/fields.rst:199
msgid "但总体来看，两个方法优劣差异并不明显，各有利弊。"
msgstr ""

#: ../../design/fields.rst:201
msgid "cartesian/join的设计"
msgstr ""

#: ../../design/fields.rst:203
msgid ""
"如果直接复用旧的cartesian，则返回的是一个每个元素是({}, "
"{})的PCollection，则此后，就无法再调用schema相关操作了，且性能也较低。 这个接口有两种可能的实现，来让用户使用起来更为方便。"
msgstr ""

#: ../../design/fields.rst:206
msgid "方案一:"
msgstr ""

#: ../../design/fields.rst:208 ../../design/fields.rst:218
msgid "a = SchemaPCollection{a, b, c}"
msgstr ""

#: ../../design/fields.rst:210
msgid "# 我们把一个有a,b,c三列的SchemaPCollection记作SchemaPCollection{a,b,c}"
msgstr ""

#: ../../design/fields.rst:212 ../../design/fields.rst:220
msgid "b = SchemaPCollection{a, d}"
msgstr ""

#: ../../design/fields.rst:214
msgid "schema.cartesian(a, b) 返回的是 SchemaPCollection{0.a, 0.b, 0.c, 1.a, 1.d}"
msgstr ""

#: ../../design/fields.rst:216
msgid "方案二："
msgstr ""

#: ../../design/fields.rst:222
msgid ""
"如果是两个SchemaPCollection（或可转为SchemaPCollection的类型），则直接修改原cartesian函数， "
"返回的类型表面看来和原来的cartesian一模一样，但是不同之处是可以直接调用select/agg， "
"select_fn传入两个{}，分别表示两个表里对应的多个PObject(PCollection)"
msgstr ""

#: ../../design/fields.rst:228
msgid ""
"schema.cartesian(a, b).apply(schema.select, lambda a, b: {'name': "
"a['name'] + b['name']})"
msgstr ""

#: ../../design/fields.rst:230
msgid "用户也可以直接把a.cartesian(b)返回的类型当作每个元素是一个tuple(dict, dict)的PCollection用。"
msgstr ""

#: ../../design/fields.rst:232
msgid "类似的, schema.join(a, b, a['id'] == b['searchid'])返回类型与cartesian返回的类型一样一样。"
msgstr ""

#: ../../design/fields.rst:234
msgid "方案三："
msgstr ""

#: ../../design/fields.rst:236
msgid "cartesian不允许用户有重复字段名，或者如果有重复则以左边的为准。"
msgstr ""

#: ../../design/fields.rst:238
msgid "max_elements/sort_by等接口设计"
msgstr ""

#: ../../design/fields.rst:240
msgid ""
"用户可以直接使用PCollection上的max/min/max_elements/min_elements/sort_by来完成相应的功能， "
"但由于出现dict操作，性能会比较慢，并且无法在用户无感知的情况下完成优化。 "
"所以需要提供特殊的这几个函数，但用户如果使用原来接口，也能满足其需求。"
msgstr ""

#: ../../design/fields.rst:244
msgid ""
"这里主要还是受限于python语言本身，导致将接口的dict设计成一个结构体类似的对象， 将取字典数据的操作改为取成员，性能也不会有多大改善。 "
"如果是一些编译型语言，可以把SchemaPCollection的元素设置成一种满足特定约束的对象 "
"（如JavaBean对象），这样，因为在对象中设置、读取某个字段避免了hash操作，可以大大提高性能。"
msgstr ""

#: ../../design/fields.rst:251
msgid "实现"
msgstr ""

#: ../../design/fields.rst:253
msgid "API层接口实现"
msgstr ""

#: ../../design/fields.rst:255
msgid ""
"为了让SchemaPCollection看起来和PCollection一样，能够执行任意的PCollection上的操作， "
"可以让SchemaPCollection派生自PCollection，并且里面的数据类型确实是dict。 "
"但，同时，在SchemaPCollection里有一个成员变量，是一个数据类型为tuple的PCollection， "
"另有成员标识出各个字段名，如果是任意的字段操作，则从数据类型为tuple的PCollection进行计算， "
"构造出新的SchemaPCollection。 "
"按照这种方案，可以使得，如果用户没有把SchemaPCollection当成普通的PCollection进行普通PCollection的操作， "
"则计算过程中生成的所有元素类型为{}的PCollection都不会在有效路径上， "
"都会因为下游没有输出结点而在优化时被删除。从而使得计算过程中不会出现{}，避免了引入{}借来的开销。"
msgstr ""

#: ../../design/fields.rst:264
msgid "from_tuple/to_tuple/group_by/flatten实现都比较简单，这里略过实现方案。"
msgstr ""

#: ../../design/fields.rst:266
msgid ""
"agg函数实现时，可以查出有哪些字段，调用多次map，把每个字段都map出一个PCollection，然后拼到dict中， "
"作为参数调用用户传入的函数，调用完成后，将用户返回的dict中的多个字段进行cartesian， "
"生成每个元素是tuple的PCollection，然后用该PCollection生成每个元素是dict的SchemaPCollection。"
msgstr ""

#: ../../design/fields.rst:270
msgid ""
"select函数实现时，需要先将原数据进行一个特殊的group_by_every_record的操作（后述如何实现该操作）， "
"该操作会生成一个PTable,key是一个UniqID,value是每条数据的PObject。然后， "
"可以利用该PObject进行map生成各个字段对应的PObject，拼成dict传递给用户，后续处理与agg函数实现类似。"
msgstr ""

#: ../../design/fields.rst:274
msgid "为何非要搞一个group_by_every_record，可以考虑下边的例子：::"
msgstr ""

#: ../../design/fields.rst:280
msgid ""
"另外，需要注意，SchemaPCollection的count/take等功能，可以重写一下，以便从tuple的PCollection上出发， "
"避免生成字典。"
msgstr ""

#: ../../design/fields.rst:283
msgid "group_by_every_record如何实现"
msgstr ""

#: ../../design/fields.rst:285
msgid ""
"group_by_every_record就是一种特殊的Shuffle， "
"在LogicalPlan里添加一种特殊的ShuffleNode，该ShuffleNode性质在Planner层做优化时， "
"与DistribteByDefault完全一致，可以完全复用相关Planner层代码。"
msgstr ""

#: ../../design/fields.rst:289
msgid ""
"在Runtime层需要实现一种特殊的ShuffleExecutor，它每读到一条正常的Shuffle数据， "
"都需要调用一次所有孩子的BeginGroup/FinishGroup。"
msgstr ""

#: ../../design/fields.rst:292
msgid ""
"另外，如果要支持select时可传入side_input/broadcast，需要支持同一ShuffleScope下存在BroadcastShuffleNode，"
" 那就需要让GroupByEveryRecordShuffleExecutor可以在Broadcast数据全部到达之前， "
"把另外其它路的数据全部缓存下来，直到所有Broadcast数据到达之后，再回放每条数据调用BeginGroup/FinishGroup， "
"以及在每个Group内都把Broadcast数据回放一遍。 "
"（由于目前框架问题，这么简单一个需求实际实现时也略复杂，也许重构框架时可以考虑一下这个问题）"
msgstr ""

#: ../../design/fields.rst:298
msgid ""
"另有一个需要注意的地方是，group_by_every_record不可使用group_by一个random uniqid的方法实现， "
"因为出现不确定性的计算并用它来进行partition的话，可能在MR框架failover时产生错误。 "
"同样的，在全局调用group_by_every_record的话，它应该按照record本身来计算hash进行partition， "
"而不应该是随便的生成一个key告诉MR框架，以防重算是一条数据两次分给了不同的下游，导致failover时出错。"
msgstr ""

#: ../../design/fields.rst:303
msgid "sort_by之后agg需要保证agg里收到的数据的顺序，该如何保证？"
msgstr ""

#: ../../design/fields.rst:305
msgid ""
"我们的sort_by操作只保证后续的一个操作有序，不保证后续所有操作有序。 "
"这里为了保证sort_by后agg里的操作有序，只能通过一个trick的方案， "
"即在sort_by之后如果调用的是agg，则添加一个什么事儿也不干的NonPartial的Processor "
"来强迫结点不前移，保证后续的agg操作都有序。"
msgstr ""

#: ../../design/fields.rst:310
msgid "高级用户教"
msgstr ""

#: ../../design/fields.rst:313
msgid "性能分析"
msgstr ""

#: ../../design/fields.rst:315
msgid "大部分场景下，数据计算时都不会真正出现dict（所有dict结点都被Planner优化删除了），所以并不会影响性能。"
msgstr ""

#: ../../design/fields.rst:317
msgid "另外，select之类的操作，由于选取字段的map函数会被前移，所以，会使得只有需要用到的数据才会过shuffle， 进而提升性能。"
msgstr ""

#: ../../design/fields.rst:320
msgid ""
"但，如果用户真的拿它当作元素为{}的PCollection用，调用map等操作时，确实会有性能损失，但如果是高级用户， "
"可以轻松的避免写出类似的代码而完成同样的功能。"
msgstr ""

#: ../../design/fields.rst:325
msgid "缺陷与未来可能的优化点"
msgstr ""

#: ../../design/fields.rst:327
msgid "由于缺少一层字段相关planner层，无法完成高级字段优化。 未来可以添加一层优化层，将操作记录下来，翻译成flume的logical plan。"
msgstr ""

#: ../../design/fields.rst:331
msgid "暂未实现直接可执行SQL语句的功能。"
msgstr ""

#: ../../design/fields.rst:331
msgid "类似于DataFrame和Spark-SQL的整合，这里也需要bigflow与wing进行整合，才能更好的完成此功能。"
msgstr ""

#: ../../design/fields.rst:334
msgid "可以重新实现一个FieldsDictSerde，让它的Deserialize返回一个对象，该对象重写了[]操作符，"
msgstr ""

#: ../../design/fields.rst:334
msgid ""
"在用户调用[]操作符时才去进行反序列化对应的列。实现与Spark Dataset类似的效果。 "
"但缺点依然是要进行hash操作（或者取字段的操作，在python里性能较差）。"
msgstr ""

