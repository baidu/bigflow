# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, Baidu
# This file is distributed under the same license as the Bigflow Python
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Bigflow Python 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-01-02 17:07+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.5.1\n"

#: ../../quickstart.rst:2
msgid "快速入门"
msgstr ""

#: ../../quickstart.rst:4
msgid "`在Python shell中使用Bigflow Python`_"
msgstr ""

#: ../../quickstart.rst:6
msgid "`准备`_"
msgstr ""

#: ../../quickstart.rst:7
msgid "`更多的变换操作`_"
msgstr ""

#: ../../quickstart.rst:9
msgid "`完整的程序`_"
msgstr ""

#: ../../quickstart.rst:11
msgid "`批处理引擎（spark）`_"
msgstr ""

#: ../../quickstart.rst:13
msgid "`进阶教程`_"
msgstr ""

#: ../../quickstart.rst:15
msgid ""
"本教程旨在提供一个使用Bigflow Python的快速上手演示。教程首先会通过在Python交互式环境(Interactive "
"Shell)中一步一步展示Bigflow Python的基本概念和API，然后演示如何写一个完整的Bigflow "
"Python程序。对于深入的概念和用法，请参照 :doc:`编程指南 <guide>` 部分。"
msgstr ""

#: ../../quickstart.rst:18
msgid "在Python shell中使用Bigflow Python"
msgstr ""

#: ../../quickstart.rst:21
msgid "准备"
msgstr ""

#: ../../quickstart.rst:23
msgid ""
"Bigflow Python工作在Python "
"2.7环境中(其它版本尚未测试)。它使用标准的CPython解释器，同时用户也能够在代码中使用第三方的Python库。"
msgstr ""

#: ../../quickstart.rst:25
msgid "获取 `bigflow_python.tar.gz <https://github.com/baidu/bigflow/releases>`_"
msgstr ""

#: ../../quickstart.rst:28
msgid ""
"保证系统环境中已经安装好hadoop client，并设置好HADOOP_HOME，Bigflow "
"Python需要从Hadoop配置文件中读取相应的配置来访问HDFS。 保证系统环境中已经安装好spark "
"client，并设置好SPARK_HOME，Bigflow Python需要从Spark配置文件中读取相应的配置来访问Spark。 "
"保证系统环境中已经安装好了Java，并设置好了JAVA_HOME，需要使用java来运行spark。"
msgstr ""

#: ../../quickstart.rst:32
msgid "用户通过 :doc:`公有云 <bigflow_on_cloud>` 可以更方便的是使用Bigflow"
msgstr ""

#: ../../quickstart.rst:34
msgid "运行 `bigflow/bin/pyrun` 即可在Python交互式环境中使用Bigflow Python。"
msgstr ""

#: ../../quickstart.rst:36
msgid "接下来，我们可以导入相关的module了::"
msgstr ""

#: ../../quickstart.rst:40
msgid ""
"Bigflow Python任务通过 `pipeline` "
"进行定义，它通过一些列对抽象数据集的变换用户计算任务。同时，pipeline也代表任务最终被提交到的计算引擎上。我们可以首先创建一个本地引擎来快速地试用::"
msgstr ""

#: ../../quickstart.rst:44
msgid "接下来可以读一个文件::"
msgstr ""

#: ../../quickstart.rst:50
msgid ""
"`pipeline.read()` 将本地文件映射为一个 `P类型` 的实例，更确切的说，是一个 `PCollection` "
"。PCollection可以看作是一个分布式的Python `list` "
"结构。TextFile表示读取的类型为文本文件，它会将文本的每一行作为PCollection的元素。注意，这时我们还没有真正地读取数据，仅仅记录了一个文本文件到PCollection的映射，因此"
" `print text` 显示的内容为省略号(\"`[...]`\")。我们可以使用 `get()` "
"方法触发Pipeline计算，将PCollection转化为一个Python的内置list::"
msgstr ""

#: ../../quickstart.rst:55
msgid ""
"PCollection定义了一系列的变换方法方便我们对其表示的数据进行计算，例如，可以使用 `count()` "
"方法统计元素的个数，也就是输入文本的行数::"
msgstr ""

#: ../../quickstart.rst:61
msgid ""
"记住P类型实例的变换结果是另一个P类型实例，这次我们看到line_num通过一个 `o` "
"表示它是另一种P类型，PObject，它对应于单个值。我们可以再次调用 `get()` 方法看到结果::"
msgstr ""

#: ../../quickstart.rst:66
msgid "我们可以再使用一个 `distinct()` 方法得到text中所有的不重复元素::"
msgstr ""

#: ../../quickstart.rst:72
msgid ""
"`distinct()` 方法的返回结果是一个PCollection，我们仍然可以使用 `get()` 方法得到其内容，或是使用 "
"`Pipeline.write()` 方法把结果写到文件中::"
msgstr ""

#: ../../quickstart.rst:76
msgid ""
"与 `read()` 方法类似，调用 `write()` 并不会马上触发文件的写操作，而仅仅将这个过程记录下来。这次我们可以使用 "
"`Pipeline.run()` 触发Pipeline计算::"
msgstr ""

#: ../../quickstart.rst:80
msgid "这时，distinct_lines的内容真正被写到了我们指定的输出路径中。"
msgstr ""

#: ../../quickstart.rst:82
msgid ""
"回顾一下，Bigflow Python会仅可能地推迟Pipeline的计算来对整个计算过程进行优化。触发计算的方式只有两种： `get()` 和 "
"`run()` 方法。"
msgstr ""

#: ../../quickstart.rst:85
msgid "更多的变换操作"
msgstr ""

#: ../../quickstart.rst:87
msgid "Bigflow Python提供了众多的变换支持从简单到复杂的计算逻辑。比如说现在我们希望得到之前的文本文件中，单词最多的那一行::"
msgstr ""

#: ../../quickstart.rst:93
msgid ""
"第一行代码使用了 `map()` 变换，将每一行映射为一个tuple -- (单词数, "
"行内容)，映射结果为另一个PCollection；第二行代码使用 `reduce()` "
"变换，将PCollection中的每两个元素进行比较，返回单词数更大的元素，最终将所有的元素聚合为一，返回一个PObject。这里的 "
"`map()` 和 `reduce()` 用法非常类似于Python内置的 `map() "
"<https://docs.python.org/2/library/functions.html#map>`_ 和 `reduce() "
"<https://docs.python.org/2/library/functions.html#reduce>`_ 。 "
"变换的参数是一个方法，例子中是Python的 `匿名表达式(lambdas) "
"<https://docs.python.org/2/reference/expressions.html#lambda>`_ "
"。我们也可以显式定义方法并使用::"
msgstr ""

#: ../../quickstart.rst:105
msgid ""
"在当前的分布式计算领域，广为人知的范式便是MapReduce。在Bigflow "
"Python中，用户能够轻易地实现一个MapReduce范式，比如以经典的Word Count为例::"
msgstr ""

#: ../../quickstart.rst:113
msgid ""
"第一行代码将输入的每一行映射为多个单词( `flat_map()` 变换是一个1到N的映射)，第二行使用 `group_by()` "
"变换根据单词进行分组。分组的结果是一种新的P类型 -- PTable。简单而言，PTable可以看作是分布式的Python `dict` "
"类型，其具有key到另一个P类型的映射::"
msgstr ""

#: ../../quickstart.rst:118
msgid ""
"例子中，groups是一个以单词为key，PCollection为value的PTable，PCollection的包含着多个'1'。我们可以使用"
" `apply_values()` 方法应用任何的变换到value，也就是PCollection上。例如，之前用过的 "
"`transforms.count()` ::"
msgstr ""

#: ../../quickstart.rst:124
msgid "现在结果是另一个PTable，value变为了PObject(单词数量)。"
msgstr ""

#: ../../quickstart.rst:126
msgid "PTable可以通过 `flatten()` 变换转换为一个PCollection::"
msgstr ""

#: ../../quickstart.rst:132
msgid "PCollection的元素为(key, value) tuple::"
msgstr ""

#: ../../quickstart.rst:137
msgid "Bigflow Python中所有的变换可以在 `transforms` 查看接口说明和用法。"
msgstr ""

#: ../../quickstart.rst:140
msgid "完整的程序"
msgstr ""

#: ../../quickstart.rst:143
msgid "批处理引擎（spark）"
msgstr ""

#: ../../quickstart.rst:145
msgid "之前的例子中，Pipeline运行在本地引擎上，生产环境中我们可以使用spark引擎处理真正的大规模数据。"
msgstr ""

#: ../../quickstart.rst:147
msgid "把所有的代码放到一个py文件中，在创建Pipeline的时候指定\"spark\"作为Pipeline类型::"
msgstr ""

#: ../../quickstart.rst:164
msgid "运行\"bin/pyrun word_cnt.py\"便可以把任务提交到spark上。"
msgstr ""

#: ../../quickstart.rst:167
msgid "更多使用示例"
msgstr ""

#: ../../quickstart.rst:168
msgid ""
"`examples "
"<https://github.com/baidu/bigflow/tree/master/bigflow_python/python/bigflow/example>`_"
msgstr ""

#: ../../quickstart.rst:171
msgid "进阶教程"
msgstr ""

#: ../../quickstart.rst:173
msgid "更多的概念和介绍，请参照Bigflow Python :doc:`编程指南 <guide>`"
msgstr ""

#: ../../quickstart.rst:174
msgid "Bigflow Python :doc:`API索引 <rst/modules>` 参考所有API的说明。"
msgstr ""

